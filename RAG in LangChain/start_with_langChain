import json
import os
from typing import List, Dict, Callable
import pandas as pd
import numpy as np
import requests
from openai import OpenAI
from sklearn.manifold import TSNE
from adjustText import adjust_text
import matplotlib.pyplot as plt
import toml
import sqlite3
import bs4
from langchain_community.document_loaders import WebBaseLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma


#load text, that will be used as a DB info for RAG
loader = WebBaseLoader(
    web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
    bs_kwargs=dict(
        parse_only=bs4.SoupStrainer(
            class_=("post-content", "post-title", "post-header")
        )
    ),
)
docs = loader.load()

#split the text
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
all_splits = text_splitter.split_documents(docs)

# Load API key
secrets = toml.load(".key/secrets.toml")

os.environ["OPENAI_API_KEY"] = secrets["OPENAI_API_KEY"]

# ✅ create vector store in ChromaDB
embeddings = OpenAIEmbeddings()
vector_store = Chroma(
    collection_name="agents_article",
    embedding_function=embeddings,
    persist_directory="./chroma_db",  # optional (saves locally)
)

#Store info in ChromaDB
_ = vector_store.add_documents(documents=all_splits)
print("✅ Added", len(all_splits), "chunks to Chroma")